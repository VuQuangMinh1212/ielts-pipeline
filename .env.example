# Google Gemini API (existing)
GENAI_API_KEY=your_gemini_api_key_here

# Database (if using)
DATABASE_URL=postgresql://user:password@localhost/ielts_db

# Training Configuration
MODEL_NAME=qwen  # Options: qwen, phi2, gemma
TRAINING_EPOCHS=3
BATCH_SIZE=1
GRADIENT_ACCUMULATION_STEPS=4
LEARNING_RATE=2e-4
MAX_SEQ_LENGTH=512

# Dataset Configuration
DATASET_PATH=./data/ielts_training_data.jsonl
TRAINING_OUTPUT_DIR=./models/ielts-finetuned

# Inference Configuration
INFERENCE_BACKEND=vllm  # Options: vllm, llamacpp, autotrain
LOCAL_MODEL_PATH=./models/ielts-finetuned
GPU_MEMORY_UTILIZATION=0.9
MAX_TOKENS=512
TEMPERATURE=0.7

# Deployment Options
USE_LOCAL_MODEL=false  # true to use fine-tuned model, false for Gemini
ENABLE_GPU=true  # false for CPU-only inference

# vLLM Specific
VLLM_QUANTIZATION=awq  # Options: awq, gptq, squeezellm, or none

# llama.cpp Specific  
GGUF_MODEL_PATH=./models/ielts-finetuned/model.gguf
LLAMA_CPP_THREADS=4

# Monitoring
ENABLE_METRICS=true
METRICS_PORT=9090
